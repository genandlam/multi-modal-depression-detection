{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:  ['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from plot_metrics import plot_accuracy, plot_loss, plot_roc_curve\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, BatchNormalization, Activation, \\\n",
    "                         Dropout, MaxPooling1D, GlobalAveragePooling1D, \\\n",
    "                         GlobalMaxPooling1D, Lambda, Concatenate, Dense, regularizers\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import optimizers, activations\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import load_model\n",
    "np.random.seed(15)  # for reproducibility\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "print(\"Using GPU: \", K.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_file(file_name):\n",
    "    path = '../feedforward/'\n",
    "    outfile = path + file_name\n",
    "    X = np.load(outfile)\n",
    "    X = X['arr_0']\n",
    "    return X\n",
    "\n",
    "def retrieve_file_no_aug(file_name):\n",
    "    path = '../data/raw_data/processed_topic/'\n",
    "    outfile = path + file_name\n",
    "    X = np.load(outfile)\n",
    "    X = X['arr_0']\n",
    "    return X\n",
    "\n",
    "def preprocess(X, max_len, num_bins):\n",
    "    \"\"\"\n",
    "    Preprocess input Xs to a numpy array where every training sample is zero padded \n",
    "    to constant time dimension (max_len) and contains num_bins frequency bins.\n",
    "    \n",
    "    Args:\n",
    "        X: numpy array of numpy arrays (X), each of which is of different time dimension \n",
    "           but same mel dimension (usually 128)\n",
    "        max_len: Length up to which each np.array in X is padded with 0s\n",
    "        num_bins: Constant mel dimension\n",
    "    \n",
    "    Returns:\n",
    "        X_proc: single numpy array of shape (X.shape[0], max_len, num_bins), which is fed into 1D CNN  \n",
    "    \"\"\"\n",
    "    X_proc = np.zeros([X.shape[0], max_len, num_bins])\n",
    "    for idx, x in enumerate(X):\n",
    "        if x.shape[0] < max_len:\n",
    "            # Pad sequence (only in time dimension) with 0s\n",
    "            x = np.pad(x, pad_width=((0, max_len - x.shape[0]), (0,0)), mode='constant')\n",
    "        else:\n",
    "            # Trim sequence to be within max_len timesteps\n",
    "            x = x[:max_len, :]\n",
    "        # Update processed sequences\n",
    "        X_proc[idx, :, :] = x\n",
    "    return X_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_confusion_matrix(y_test, y_test_pred):\n",
    "    \"\"\"\n",
    "    Make confusion matrix with format:\n",
    "                  -----------\n",
    "                  | TP | FP |\n",
    "                  -----------\n",
    "                  | FN | TN |\n",
    "                  -----------\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : ndarray - 1D\n",
    "    y_pred : ndarray - 1D\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray - 2D\n",
    "    \"\"\"\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    print(\"\\nConfusion Matrix: (sklearn)\\n\")\n",
    "    print(cnf_matrix)\n",
    "    [[tn, fp], [fn, tp]] = cnf_matrix\n",
    "    return np.array([[tp, fp], [fn, tn]])\n",
    "\n",
    "\n",
    "def model_performance(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Evaluation metrics for network performance.\n",
    "    \"\"\"\n",
    "    y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "    y_train_pred = np.argmax(model.predict(X_train), axis=-1)\n",
    "\n",
    "    # Computing confusion matrix for test dataset\n",
    "    conf_matrix = standard_confusion_matrix(y_test, y_test_pred)\n",
    "    print(\"\\nConfusion Matrix:\\n\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    target_name=['non-depressed','depressed']\n",
    "    clf_report = classification_report(y_test, y_test_pred, target_names=target_name)\n",
    "    print(\"\\nClassification Report (sklearn):\\n\")\n",
    "    print(clf_report)\n",
    "    \n",
    "    print(\"\\nF1-Score: {}\".format(sklearn.metrics.f1_score(y_test, y_test_pred)))\n",
    "    return y_train_pred, y_test_pred, conf_matrix, clf_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of training X: 5499 (timesteps)\n",
      "Number of mel bins:  128\n",
      "(307, 5499, 128) (33, 5499, 128)\n",
      "(307, 2) (33, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train_no_aug = retrieve_file_no_aug('train_samples.npz')\n",
    "y_train_no_aug = retrieve_file_no_aug('train_labels.npz')\n",
    "\n",
    "X_test = retrieve_file_no_aug('test_samples.npz')\n",
    "y_test = retrieve_file_no_aug('test_labels.npz')\n",
    "\n",
    "X_train3 = retrieve_file('train_samples_200.npz')\n",
    "y_train3 = retrieve_file('train_labels_200.npz')\n",
    "\n",
    "X_train=np.concatenate((X_train_no_aug,X_train3), axis=0)\n",
    "y_train=np.concatenate((y_train_no_aug,y_train3), axis=0)\n",
    "\n",
    "NB_CLASSES = 2\n",
    "# Maximum time duration among training samples \n",
    "MAX_LEN = np.max([X_train[i].shape[0] for i in range(len(X_train))])\n",
    "print(\"Maximum length of training X: {} (timesteps)\".format(MAX_LEN))\n",
    "# Number of mel bins in training samples\n",
    "NUM_BINS = X_train[0].shape[1]\n",
    "print(\"Number of mel bins: \", NUM_BINS)\n",
    "\n",
    "# Preprocess input Xs\n",
    "X_train = preprocess(X_train, max_len=MAX_LEN, num_bins=NUM_BINS)\n",
    "X_test = preprocess(X_test, max_len=MAX_LEN, num_bins=NUM_BINS)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix: (sklearn)\n",
      "\n",
      "[[19  2]\n",
      " [ 5  7]]\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 7  2]\n",
      " [ 5 19]]\n",
      "\n",
      "Classification Report (sklearn):\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-depressed       0.79      0.90      0.84        21\n",
      "    depressed       0.78      0.58      0.67        12\n",
      "\n",
      "  avg / total       0.79      0.79      0.78        33\n",
      "\n",
      "\n",
      "F1-Score: 0.666666666667\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "cnn_model=load_model('cnn_augm_run500_f10.666666666667.h5')\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                       optimizer=Adam(lr=0.000625),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "y_train_pred, y_test_pred, conf_matrix, clf_report = model_performance(cnn_model, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangsheng/anaconda2/lib/python2.7/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "cnn_featurizer = load_model(\"cnn_featurizer_augm_run500_0.666666666667f1.h5\")\n",
    "cnn_featurizer.compile(loss='categorical_crossentropy',\n",
    "                       optimizer=Adam(lr=0.000625),\n",
    "                       metrics=['accuracy'])\n",
    "#cnn_featurizer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 64)\n",
      "(33, 64)\n"
     ]
    }
   ],
   "source": [
    "train_audio_features = cnn_featurizer.predict(X_train)\n",
    "print(train_audio_features.shape)\n",
    "test_audio_features = cnn_featurizer.predict(X_test)\n",
    "print(test_audio_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(fname=\"train_audio_features_augm200.txt\", X=train_audio_features)\n",
    "np.savetxt(fname=\"test_audio_features_augm200.txt\", X=test_audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ..., \n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt(\"train_audio_features_augm200.txt\") == train_audio_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
