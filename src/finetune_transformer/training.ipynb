{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "from finetune import Classifier\n",
    "from finetune.config import get_default_config, get_small_model_config, GridSearchable, get_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model hyperparameters through custom config\n",
    "- Loads small model (6 layer transformer) config and then overwrites certain values\n",
    "- Adding GridSearchable to a param makes model try every value of it in grid search\n",
    "    - If you don't do grid search, model will use the default value provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_config():\n",
    "    # conf = get_default_config()  \n",
    "    conf = get_small_model_config()\n",
    "    conf.l2_reg = GridSearchable(0.01, [0.0, 0.1, 0.01, 0.001]) \n",
    "    conf.lr = GridSearchable(6.25e-6, [6.25e-4, 6.25e-5, 6.25e-6])\n",
    "    conf.n_epochs = GridSearchable(1, [1, 2, 3])\n",
    "    conf.batch_size = 10\n",
    "    conf.class_weights = 'linear'\n",
    "    conf.oversample = False  # Do not use if using class_weights\n",
    "    conf.low_memory_mode = True\n",
    "    conf.val_size = 0.0  # Do not perform validation right now\n",
    "    conf.val_interval = 10000  # Do not perform validation right now\n",
    "    print(\"Config: \", conf)\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "- Load from training data file which contains topic modelling and does not contain augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (942, 2)\n",
      "Testing data: (33, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_train = pd.read_csv(\"data_train_aug.csv\")\n",
    "print(\"Training data: {}\".format(data_train.shape))\n",
    "data_test = pd.read_csv(\"data_test_aug.csv\")\n",
    "print(\"Testing data: {}\".format(data_test.shape))\n",
    "\n",
    "trainX, trainY = data_train.Text, data_train.Targets\n",
    "testX, testY = data_test.Text, data_test.Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Classifier model\n",
    "- Currently not performing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:  {'grid_searchable': {'n_epochs': [1, 2, 3], 'l2_reg': [0.0, 0.1, 0.01, 0.001], 'lr': [0.000625, 6.25e-05, 6.25e-06]}, 'batch_size': 10, 'visible_gpus': [0], 'n_epochs': 1, 'seed': 42, 'max_length': 512, 'weight_stddev': 0.02, 'chunk_long_sequences': False, 'low_memory_mode': True, 'interpolate_pos_embed': True, 'embed_p_drop': 0.1, 'attn_p_drop': 0.1, 'resid_p_drop': 0.1, 'clf_p_drop': 0.1, 'l2_reg': 0.01, 'vector_l2': False, 'regularize_deviation': False, 'b1': 0.9, 'b2': 0.999, 'epsilon': 1e-08, 'lr_schedule': 'warmup_linear', 'lr': 6.25e-06, 'lr_warmup': 0.002, 'max_grad_norm': 1, 'lm_loss_coef': 0.0, 'summarize_grads': False, 'verbose': True, 'val_size': 0.0, 'val_interval': 10000, 'val_window_size': 5, 'rolling_avg_decay': 0.99, 'lm_temp': 0.2, 'seq_num_heads': 16, 'pad_token': '<PAD>', 'subtoken_predictions': False, 'multi_label_sequences': False, 'multi_label_threshold': 0.5, 'autosave_path': None, 'tensorboard_folder': None, 'log_device_placement': False, 'soft_device_placement': True, 'save_adam_vars': False, 'num_layers_trained': 6, 'train_embeddings': True, 'class_weights': 'linear', 'oversample': False, 'params_device': 'cpu', 'n_heads': 8, 'n_layer': 6, 'act_fn': 'gelu', 'n_embed': 512, 'base_model_path': '/home/ckjoshi9/depression_finetune/finetune/finetune/model/SmallBaseModel.jl'}\n"
     ]
    }
   ],
   "source": [
    "model = Classifier(config=get_custom_config())\n",
    "\n",
    "# Uncomment below to do grid search (And comment out above model)\n",
    "\n",
    "# best_config = Classifier.finetune_grid_search_cv(trainX, trainY, n_splits=2, config=get_custom_config(), eval_fn=lambda pred, true: f1_score(pred, true), test_size=0.1)\n",
    "# print(\"Best training parameters: \\n{}\".format(best_config))\n",
    "# model = Classifier(config=best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ckjoshi9/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/function.py:986: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckjoshi9/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<finetune.classifier.Classifier at 0x7f114c7288d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.finetune(np.array(trainX), np.array(trainY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.67 for a 0.36 class balance\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      1.00      0.79        21\n",
      "          1       1.00      0.08      0.15        12\n",
      "\n",
      "avg / total       0.78      0.67      0.56        33\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[21  0]\n",
      " [11  1]]\n",
      "\n",
      "F1-Score:  0.15384615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Compute metrics\n",
    "predY = model.predict(testX)\n",
    "accuracy = np.mean(predY == testY)\n",
    "class_balance = np.mean(testY)\n",
    "print('Test Accuracy: {:0.2f} for a {:0.2f} class balance'.format(accuracy, class_balance))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(model.label_encoder.transform(testY), model.label_encoder.transform(predY)))\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(testY, predY))\n",
    "print(\"\\nF1-Score: \", f1_score(predY, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample results (best run)\n",
    "\n",
    "```\n",
    "Training data: (107, 2)\n",
    "Testing data: (33, 2)\n",
    "Config:  {'grid_searchable': {'n_epochs': [1, 2, 3], 'l2_reg': [0.0, 0.1, 0.01, 0.001], 'lr': [0.000625, 6.25e-05, 6.25e-06]}, 'batch_size': 10, 'visible_gpus': [0], 'n_epochs': 1, 'seed': 42, 'max_length': 512, 'weight_stddev': 0.02, 'chunk_long_sequences': False, 'low_memory_mode': True, 'interpolate_pos_embed': True, 'embed_p_drop': 0.1, 'attn_p_drop': 0.1, 'resid_p_drop': 0.1, 'clf_p_drop': 0.1, 'l2_reg': 0.01, 'vector_l2': False, 'regularize_deviation': False, 'b1': 0.9, 'b2': 0.999, 'epsilon': 1e-08, 'lr_schedule': 'warmup_linear', 'lr': 6.25e-06, 'lr_warmup': 0.002, 'max_grad_norm': 1, 'lm_loss_coef': 0.0, 'summarize_grads': False, 'verbose': True, 'val_size': 0.0, 'val_interval': 10000, 'val_window_size': 5, 'rolling_avg_decay': 0.99, 'lm_temp': 0.2, 'seq_num_heads': 16, 'pad_token': '<PAD>', 'subtoken_predictions': False, 'multi_label_sequences': False, 'multi_label_threshold': 0.5, 'autosave_path': None, 'tensorboard_folder': None, 'log_device_placement': False, 'soft_device_placement': True, 'save_adam_vars': False, 'num_layers_trained': 6, 'train_embeddings': True, 'class_weights': 'linear', 'oversample': True, 'params_device': 'cpu', 'n_heads': 8, 'n_layer': 6, 'act_fn': 'gelu', 'n_embed': 512, 'base_model_path': '/home/ckjoshi9/depression_finetune/finetune/finetune/model/SmallBaseModel.jl'}\n",
    "/home/ckjoshi9/depression_finetune/finetune/finetune/base.py:406: UserWarning: Model will only receive {} weight updates.  This may not be sufficient to find a good minima.Please consider lowering `config.batch_size` or providing more labeled training data to thet model.\n",
    "  \"Model will only receive {} weight updates.  This may not be sufficient to find a good minima.\"\n",
    "/home/ckjoshi9/miniconda3/envs/finetune/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
    "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
    "                                                                                \n",
    "Test Accuracy: 0.45 for a 0.36 class balance\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.71      0.24      0.36        21\n",
    "          1       0.38      0.83      0.53        12\n",
    "\n",
    "avg / total       0.59      0.45      0.42        33\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "[[ 5 16]\n",
    " [ 2 10]]\n",
    "\n",
    "F1-Score:  0.5263157894736842\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(<path>)\n",
    "# del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Topic modelling + Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_config():\n",
    "    # conf = get_default_config()  \n",
    "    conf = get_small_model_config()\n",
    "    conf.l2_reg = GridSearchable(0.01, [0.0, 0.1, 0.01, 0.001]) \n",
    "    conf.lr = GridSearchable(6.25e-6, [6.25e-4, 6.25e-5, 6.25e-6])\n",
    "    conf.n_epochs = GridSearchable(1, [1, 2, 3])\n",
    "    conf.batch_size = 2\n",
    "    conf.class_weights ='linear'\n",
    "    conf.oversample = False\n",
    "    conf.low_memory_mode = True\n",
    "    conf.val_size = 0.0\n",
    "    conf.val_interval = 10000\n",
    "    print(\"Config: \", conf)\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (942, 2)\n",
      "Testing data: (33, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_train = pd.read_csv(\"data_train_aug.csv\")   # IMPORTANT: USE CORRECT TRAINING DATA\n",
    "print(\"Training data: {}\".format(data_train.shape))\n",
    "data_test = pd.read_csv(\"data_test_aug.csv\")\n",
    "print(\"Testing data: {}\".format(data_test.shape))\n",
    "trainX, trainY = data_train.Text, data_train.Targets\n",
    "testX, testY = data_test.Text, data_test.Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ckjoshi9/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/function.py:986: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckjoshi9/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<finetune.classifier.Classifier at 0x7fb326acd9b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = Classifier(get_config(**best_config))\n",
    "# Train model\n",
    "model.finetune(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99       462\n",
      "          1       0.99      1.00      0.99       480\n",
      "\n",
      "avg / total       0.99      0.99      0.99       942\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[457   5]\n",
      " [  2 478]]\n",
      "\n",
      "F1-Score:  0.9927310488058152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Compute metrics\n",
    "predY = model.predict(trainX)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(model.label_encoder.transform(trainY), model.label_encoder.transform(predY)))\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(trainY, predY))\n",
    "print(\"\\nF1-Score: \", f1_score(predY, trainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.67 for a 0.36 class balance\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.90      0.78        21\n",
      "          1       0.60      0.25      0.35        12\n",
      "\n",
      "avg / total       0.65      0.67      0.62        33\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[19  2]\n",
      " [ 9  3]]\n",
      "\n",
      "F1-Score:  0.35294117647058826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Compute metrics\n",
    "predY = model.predict(testX)\n",
    "accuracy = np.mean(predY == testY)\n",
    "class_balance = np.mean(testY)\n",
    "print('Test Accuracy: {:0.2f} for a {:0.2f} class balance'.format(accuracy, class_balance))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(model.label_encoder.transform(testY), model.label_encoder.transform(predY)))\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(testY, predY))\n",
    "print(\"\\nF1-Score: \", f1_score(predY, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Results (best run)\n",
    "\n",
    "```\n",
    "Training data: (534, 2)\n",
    "Testing data: (33, 2)\n",
    "Config:  {'grid_searchable': {'n_epochs': [1, 2, 3], 'l2_reg': [0.0, 0.1, 0.01, 0.001], 'lr': [0.000625, 6.25e-05, 6.25e-06]}, 'batch_size': 2, 'visible_gpus': [0], 'n_epochs': 1, 'seed': 42, 'max_length': 512, 'weight_stddev': 0.02, 'chunk_long_sequences': False, 'low_memory_mode': True, 'interpolate_pos_embed': True, 'embed_p_drop': 0.1, 'attn_p_drop': 0.1, 'resid_p_drop': 0.1, 'clf_p_drop': 0.1, 'l2_reg': 0.01, 'vector_l2': False, 'regularize_deviation': False, 'b1': 0.9, 'b2': 0.999, 'epsilon': 1e-08, 'lr_schedule': 'warmup_linear', 'lr': 6.25e-06, 'lr_warmup': 0.002, 'max_grad_norm': 1, 'lm_loss_coef': 0.0, 'summarize_grads': False, 'verbose': True, 'val_size': 0.0, 'val_interval': 10000, 'val_window_size': 5, 'rolling_avg_decay': 0.99, 'lm_temp': 0.2, 'seq_num_heads': 16, 'pad_token': '<PAD>', 'subtoken_predictions': False, 'multi_label_sequences': False, 'multi_label_threshold': 0.5, 'autosave_path': None, 'tensorboard_folder': None, 'log_device_placement': False, 'soft_device_placement': True, 'save_adam_vars': False, 'num_layers_trained': 6, 'train_embeddings': True, 'class_weights': 'linear', 'oversample': False, 'params_device': 'cpu', 'n_heads': 8, 'n_layer': 6, 'act_fn': 'gelu', 'n_embed': 512, 'base_model_path': '/home/ckjoshi9/depression_finetune/finetune/finetune/model/SmallBaseModel.jl'}\n",
    "WARNING:tensorflow:From /home/ckjoshi9/miniconda3/envs/finetune/lib/python3.6/site-packages/tensorflow/python/framework/function.py:986: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
    "/home/ckjoshi9/miniconda3/envs/finetune/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
    "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
    "                                                                                \n",
    "Test Accuracy: 0.85 for a 0.36 class balance\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.86      0.90      0.88        21\n",
    "          1       0.82      0.75      0.78        12\n",
    "\n",
    "avg / total       0.85      0.85      0.85        33\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "[[19  2]\n",
    " [ 3  9]]\n",
    "\n",
    "F1-Score:  0.7826086956521738\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(<path>)\n",
    "# del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_config():\n",
    "    # conf = get_default_config()  \n",
    "    conf = get_small_model_config()\n",
    "    conf.l2_reg = GridSearchable(0.01, [0.0, 0.1, 0.01, 0.001]) \n",
    "    conf.lr = GridSearchable(6.25e-6, [6.25e-4, 6.25e-5, 6.25e-6])\n",
    "    conf.n_epochs = GridSearchable(1, [1, 2, 3])\n",
    "    conf.batch_size = 10\n",
    "    conf.class_weights = 'linear'\n",
    "    conf.oversample = False\n",
    "    conf.low_memory_mode = True\n",
    "    conf.val_size = 0.0\n",
    "    conf.val_interval = 10000\n",
    "    print(\"Config: \", conf)\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_train = pd.read_csv(\"data_train_full.csv\")  # IMPORTANT: USE CORRECT TRAINING DATA\n",
    "print(\"Training data: {}\".format(data_train.shape))\n",
    "data_test = pd.read_csv(\"data_test_full.csv\")\n",
    "print(\"Testing data: {}\".format(data_test.shape))\n",
    "trainX, trainY = data_train.Text, data_train.Targets\n",
    "testX, testY = data_test.Text, data_test.Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = Classifier(config=get_custom_config())\n",
    "\n",
    "# Uncomment for grid search\n",
    "# best_config = Classifier.finetune_grid_search_cv(trainX, trainY, n_splits=2, config=get_custom_config(), eval_fn=lambda pred, true: f1_score(pred, true), test_size=0.1)\n",
    "# print(\"Best training parameters: \\n{}\".format(best_config))\n",
    "# model = Classifier(config=best_config)\n",
    "\n",
    "# Train model\n",
    "model.finetune(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "predY = model.predict(testX)\n",
    "accuracy = np.mean(predY == testY)\n",
    "class_balance = np.mean(testY)\n",
    "print('Test Accuracy: {:0.2f} for a {:0.2f} class balance'.format(accuracy, class_balance))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(model.label_encoder.transform(testY), model.label_encoder.transform(predY)))\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(testY, predY))\n",
    "print(\"\\nF1-Score: \", f1_score(predY, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Results (best run)\n",
    "\n",
    "```\n",
    "/home/ckjoshi9/depression_finetune/finetune/finetune/encoding.py:307: UserWarning: Some examples are longer than the max_length. Please trim documents or increase `max_length`. Fallback behaviour is to use the first 510 byte-pair encoded tokens\n",
    "  \"Fallback behaviour is to use the first {} byte-pair encoded tokens\".format(max_length - 2)\n",
    "Training data: (107, 2)\n",
    "Testing data: (35, 2)\n",
    "Config:  {'grid_searchable': {'n_epochs': [1, 2, 3], 'l2_reg': [0.0, 0.1, 0.01, 0.001], 'lr': [0.000625, 6.25e-05, 6.25e-06]}, 'batch_size': 10, 'visible_gpus': [0], 'n_epochs': 1, 'seed': 42, 'max_length': 512, 'weight_stddev': 0.02, 'chunk_long_sequences': False, 'low_memory_mode': True, 'interpolate_pos_embed': True, 'embed_p_drop': 0.1, 'attn_p_drop': 0.1, 'resid_p_drop': 0.1, 'clf_p_drop': 0.1, 'l2_reg': 0.01, 'vector_l2': False, 'regularize_deviation': False, 'b1': 0.9, 'b2': 0.999, 'epsilon': 1e-08, 'lr_schedule': 'warmup_linear', 'lr': 6.25e-06, 'lr_warmup': 0.002, 'max_grad_norm': 1, 'lm_loss_coef': 0.0, 'summarize_grads': False, 'verbose': True, 'val_size': 0.0, 'val_interval': 10000, 'val_window_size': 5, 'rolling_avg_decay': 0.99, 'lm_temp': 0.2, 'seq_num_heads': 16, 'pad_token': '<PAD>', 'subtoken_predictions': False, 'multi_label_sequences': False, 'multi_label_threshold': 0.5, 'autosave_path': None, 'tensorboard_folder': None, 'log_device_placement': False, 'soft_device_placement': True, 'save_adam_vars': False, 'num_layers_trained': 6, 'train_embeddings': True, 'class_weights': 'linear', 'oversample': False, 'params_device': 'cpu', 'n_heads': 8, 'n_layer': 6, 'act_fn': 'gelu', 'n_embed': 512, 'base_model_path': '/home/ckjoshi9/depression_finetune/finetune/finetune/model/SmallBaseModel.jl'}\n",
    "/home/ckjoshi9/depression_finetune/finetune/finetune/encoding.py:246: UserWarning: Document is longer than max length allowed, trimming document to 512 tokens.\n",
    "  max_length\n",
    "/home/ckjoshi9/depression_finetune/finetune/finetune/base.py:406: UserWarning: Model will only receive {} weight updates.  This may not be sufficient to find a good minima.Please consider lowering `config.batch_size` or providing more labeled training data to thet model.\n",
    "  \"Model will only receive {} weight updates.  This may not be sufficient to find a good minima.\"\n",
    "/home/ckjoshi9/miniconda3/envs/finetune/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
    "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
    "                      \n",
    "Test Accuracy: 0.51 for a 0.34 class balance\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.69      0.48      0.56        23\n",
    "          1       0.37      0.58      0.45        12\n",
    "\n",
    "avg / total       0.58      0.51      0.53        35\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "[[11 12]\n",
    " [ 5  7]]\n",
    "\n",
    "F1-Score:  0.4516129032258065\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(<path>)\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
